{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0     id keyword location country  \\\n",
      "7608        7608  10869     NaN      NaN     NaN   \n",
      "7609        7609  10870     NaN      NaN     NaN   \n",
      "7610        7610  10871     NaN      NaN     NaN   \n",
      "7611        7611  10872     NaN      NaN     NaN   \n",
      "7612        7612  10873     NaN      NaN     NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
      "7611  Police investigating after an e-bike collided ...       1  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_normalized.csv\")\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Subset only target = 1 (Only disasters)\n",
    "df = df[df['target'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove rows where 'country' is null\n",
    "df = df[df[\"country\"].notnull()]\n",
    "\n",
    "# Remove rows where 'keyword' is null\n",
    "df = df[df[\"keyword\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0     id   keyword         location country  \\\n",
      "7541        7541  10782  wreckage  New Delhi,India     IND   \n",
      "7542        7542  10783  wreckage     Xi'an, China     CHN   \n",
      "7543        7543  10784  wreckage           Mumbai     IND   \n",
      "7552        7552  10795   wrecked   Santa Cruz, CA     ARG   \n",
      "7572        7572  10823   wrecked    Manhattan, NY     USA   \n",
      "\n",
      "                                                   text  target  \n",
      "7541  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n",
      "7542  Wreckage 'conclusively confirmed' as from miss...       1  \n",
      "7543  Wreckage 'Conclusively Confirmed' as From MH37...       1  \n",
      "7552  Israel wrecked my home. Now it wants my land. ...       1  \n",
      "7572  @Kirafrog @mount_wario Did you get wrecked again?       1  \n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       keyword country\n",
      "7541  wreckage     IND\n",
      "7542  wreckage     CHN\n",
      "7543  wreckage     IND\n",
      "7552   wrecked     ARG\n",
      "7572   wrecked     USA\n"
     ]
    }
   ],
   "source": [
    "# I only need columns 'keyword' and 'country'\n",
    "df = df[[\"keyword\", \"country\"]]\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Now I want to add a new column 'type' with mappings to keywords\n",
    "\n",
    "# TOTAL\n",
    "df_total = df['country'].value_counts()\n",
    "\n",
    "# FIRE\n",
    "FIRE = ['ablaze', 'arson', 'arsonist', 'arson', 'arsonist', 'buildings%20burning', 'buildings%20on%20fire', 'burned', 'burning', 'burning%20buildings', 'bush%20fires', 'fire', 'fire%20truck', 'first%20responders', 'flames', 'forest%20fire', 'forest%20fires', 'wild%20fires', 'wildfire', 'engulfed', 'hellfire']\n",
    "\n",
    "df_fire = df[df['keyword'].isin(FIRE)]\n",
    "\n",
    "df_fire = df_fire['country'].value_counts()\n",
    "\n",
    "# EXPLOSION\n",
    "EXPLOSION = ['blew%20up', 'blown%20up', 'bomb' ,'bombed' ,'bombing' ,'detonate', 'detonation' , 'explode' ,'exploded' ,'explosion' ,'loud%20bang']\n",
    "\n",
    "df_explosion = df[df['keyword'].isin(EXPLOSION)]\n",
    "\n",
    "df_explosion = df_explosion['country'].value_counts()\n",
    "\n",
    "# TRANSPORT\n",
    "TRANSPORT = ['airplane%20accident' ,  'collide', 'collided', 'collision' ,'crash' ,'crashed' ,'wreck' ,'wreckage', 'wrecked' ,'derail', 'derailed' ,'derailment' ,'sinking', 'sunk']\n",
    "\n",
    "df_transport = df[df['keyword'].isin(TRANSPORT)]\n",
    "\n",
    "df_transport = df_transport['country'].value_counts()\n",
    "\n",
    "# TERRORISM\n",
    "TERRORISM = ['bioterrorism' ,'bioterror' ,'hijack' ,'hijacker'  ,'hijacking' ,'hostage', 'hostages' ,'suicide%20bomb' ,'suicide%20bomber' ,'suicide%20bombing', 'terrorism' ,'terrorist']\n",
    "\n",
    "df_terrorism = df[df['keyword'].isin(TERRORISM)]\n",
    "\n",
    "df_terrorism = df_terrorism['country'].value_counts()\n",
    "\n",
    "# CONSTRUCTION\n",
    "CONSTRUCTION = ['bridge%20collapse' ,'collapse',  'collapsed', 'structural%20failure']\n",
    "\n",
    "df_construction = df[df['keyword'].isin(CONSTRUCTION)]\n",
    "\n",
    "df_construction = df_construction['country'].value_counts()\n",
    "\n",
    "# WIND\n",
    "WIND = ['cyclone' , 'hurricane' ,'rainstorm', 'snowstorm' ,'storm' ,'tornado','typhoon', 'whirlwind' ,'windstorm' ,'blizzard', 'hail' ,'hailstorm', 'sandstorm', 'dust%20storm', 'violent%20storm'   ]\n",
    "\n",
    "df_wind = df[df['keyword'].isin(WIND)]\n",
    "\n",
    "df_wind = df_wind['country'].value_counts()\n",
    "\n",
    "# FLOODING\n",
    "FLOODING = ['deluge' ,'deluged' ,'drown', 'drowned', 'drowning' , 'flooding' ,'floods' ,'flood' ,'tsunami']\n",
    "\n",
    "df_flooding = df[df['keyword'].isin(FLOODING)]\n",
    "\n",
    "df_flooding = df_flooding['country'].value_counts()\n",
    "\n",
    "# HOT WEATHER\n",
    "HOT_WEATHER = ['drought' ,'heat%20wave' ]\n",
    "\n",
    "df_hot_weather = df[df['keyword'].isin(HOT_WEATHER)]\n",
    "\n",
    "df_hot_weather = df_hot_weather['country'].value_counts()\n",
    "\n",
    "# TECTONICS\n",
    "TECTONICS = ['earthquake', 'epicentre' ,'lava' ,'seismic' ,'volcano']\n",
    "\n",
    "df_tectonics = df[df['keyword'].isin(TECTONICS)]\n",
    "\n",
    "df_tectonics = df_tectonics['country'].value_counts()\n",
    "\n",
    "# FAMINE\n",
    "FAMINE = ['famine']\n",
    "\n",
    "df_famine = df[df['keyword'].isin(FAMINE)]\n",
    "\n",
    "df_famine = df_famine['country'].value_counts()\n",
    "\n",
    "# ERROSION\n",
    "ERROSION = ['landslide' , 'mudslide' ,'sinkhole', 'avalanche' ,'cliff%20fall']\n",
    "\n",
    "df_errosion = df[df['keyword'].isin(ERROSION)]\n",
    "\n",
    "df_errosion = df_errosion['country'].value_counts()\n",
    "\n",
    "# LIGHTENING\n",
    "LIGHTENING = ['lightning' ,'thunder' ,'thunderstorm']\n",
    "\n",
    "df_lightening = df[df['keyword'].isin(LIGHTENING)]\n",
    "\n",
    "df_lightening = df_lightening['country'].value_counts()\n",
    "\n",
    "# MASS MURDER\n",
    "MASS_MURDER = [ 'mass%20murder' ,'mass%20murderer']\n",
    "\n",
    "df_mass_murder = df[df['keyword'].isin(MASS_MURDER)]\n",
    "\n",
    "df_mass_murder = df_mass_murder['country'].value_counts()\n",
    "\n",
    "# NUCLEAR\n",
    "NUCLEAR = ['meltdown' ,'military' ,'natural%20disaster' ,'nuclear%20disaster', 'nuclear%20reactor' ,'radiation%20emergency']\n",
    "\n",
    "df_nuclear = df[df['keyword'].isin(NUCLEAR)]\n",
    "\n",
    "df_nuclear = df_nuclear['country'].value_counts()\n",
    "\n",
    "# INDUSTRIAL\n",
    "INDUSTRIAL = ['oil%20spill', 'electrocute' ,'electrocuted' ,'chemical%20emergency']\n",
    "\n",
    "df_industrial = df[df['keyword'].isin(INDUSTRIAL)]\n",
    "\n",
    "df_industrial = df_industrial['country'].value_counts()\n",
    "\n",
    "# DISEASE\n",
    "DISEASE = ['outbreak', 'quarantine' ,'quarantined']\n",
    "\n",
    "df_disease = df[df['keyword'].isin(DISEASE)]\n",
    "\n",
    "df_disease = df_disease['country'].value_counts()\n",
    "\n",
    "# RIOT\n",
    "RIOT = ['riot', 'rioting']\n",
    "\n",
    "df_riot = df[df['keyword'].isin(RIOT)]\n",
    "\n",
    "df_riot = df_riot['country'].value_counts()\n",
    "\n",
    "# WAR\n",
    "WAR = ['war%20zone' ,'weapon', 'weapons' ,'army', 'battle' ,'refugees']\n",
    "\n",
    "df_war = df[df['keyword'].isin(WAR)]\n",
    "\n",
    "df_war = df_war['country'].value_counts()\n",
    "\n",
    "# UNIDENTIFIED\n",
    "UNIDENTIFIED = ['accident', 'aftershock' ,'ambulance' ,'annihilated', 'annihilation' ,'apocalypse' ,'armageddon'  ,'attack', 'attacked' ,  'blaze' ,'blazing' ,'bleeding' ,'blight','blood', 'bloody', 'body%20bag', 'body%20bagging', 'body%20bags' ,'casualties' ,'casualty' ,'catastrophe', 'catastrophic' ,'crush' ,'crushed', 'curfew' , 'damage', 'danger' ,'dead' ,'death' , 'deaths' ,'debris' ,'demolish', 'demolished' ,'demolition' , 'desolate', 'desolation', 'destroy', 'destroyed', 'destruction' ,'devastated', 'devastation', 'disaster' ,'displaced',  'emergency', 'emergency%20plan' ,'emergency%20services'  ,  'evacuate', 'evacuated' ,'evacuation' , 'eyewitness' ,'fatal' ,'fatalities' ,'fatality' ,'fear' ,'flattened'  , 'harm' ,'hazard' ,'hazardous' ,  'injured' ,'injuries' ,'injury', 'inundated', 'inundation' , 'massacre' ,'mayhem' ,'obliterate', 'obliterated' , 'obliteration' ,  'pandemonium' ,'panic', 'panicking' , 'police'  ,'razed' ,'rescue' ,'rescued', 'rescuers'  , 'rubble' ,'ruin' , 'screamed' ,'screaming' ,'screams',  'siren' ,'sirens' ,'smoke' , 'stretcher' ,  'survive', 'survived' ,'survivors' , 'threat', 'tragedy' ,'trapped', 'trauma' ,'traumatised' ,'trouble' , 'twister' , 'upheaval' ,'wounded' ,'wounds' ]\n",
    "\n",
    "df_unidentified = df[df['keyword'].isin(UNIDENTIFIED)]\n",
    "\n",
    "df_unidentified = df_unidentified['country'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Join all the serieses into one big dataframe\n",
    "\n",
    "df_output = pd.DataFrame({\n",
    "    'country': list(df_output.index),\n",
    "    'total': df_total, \n",
    "    'fire': df_fire, \n",
    "    'explosion': df_explosion,\n",
    "    'transport': df_transport,\n",
    "    'terrorism': df_terrorism,\n",
    "    'construction': df_construction,\n",
    "    'wind': df_wind,\n",
    "    'flooding':df_flooding,\n",
    "    'hot_weather':df_hot_weather,\n",
    "    'tectonics': df_tectonics,\n",
    "    'famine': df_famine,\n",
    "    'errosion': df_errosion,\n",
    "    'lightening': df_lightening,\n",
    "    'mass_murder': df_mass_murder,\n",
    "    'nuclear': df_nuclear,\n",
    "    'industrial': df_industrial,\n",
    "    'disease': df_disease,\n",
    "    'riot': df_riot,\n",
    "    'war': df_war,\n",
    "    'unidentified': df_unidentified})\n",
    "\n",
    "# Save the dataframe\n",
    "df_output.to_csv(\"location_totals.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d68830897a5780e7aa2c61352aa0db10cb9911aead0795b4368918597d1e119"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}