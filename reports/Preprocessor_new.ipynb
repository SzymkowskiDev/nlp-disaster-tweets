{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ORIGINAL_PATH = \"../data/original/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Read file with datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(ORIGINAL_PATH + r\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword location                                               text  \\\n",
       "0    1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1    4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2    5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3    6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4    7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5    8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6   10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7   13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8   14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9   15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "10  16     NaN      NaN        Three people died from the heat wave so far   \n",
       "11  17     NaN      NaN  Haha South Tampa is getting flooded hah- WAIT ...   \n",
       "12  18     NaN      NaN  #raining #flooding #Florida #TampaBay #Tampa 1...   \n",
       "13  19     NaN      NaN            #Flood in Bago Myanmar #We arrived Bago   \n",
       "14  20     NaN      NaN  Damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "    target  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "5        1  \n",
       "6        1  \n",
       "7        1  \n",
       "8        1  \n",
       "9        1  \n",
       "10       1  \n",
       "11       1  \n",
       "12       1  \n",
       "13       1  \n",
       "14       1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Drop None(na) values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Delete rows with empty text values.\n",
    "These lines will not be useful to us because there is nothing to explore in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['text'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## To lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert all words to lowercase to avoid a situation where the words **Mango** and **mango** are considered different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['lower_text'] = [entry.lower() for entry in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Remove contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Change contractions __(for ex: can't've)__ to the full form of the word.\n",
    "**Ain't** and **am not** have the same meaning, but it will be easier for the program to understand if the first and second text is the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('../notebooks/en_contractions.json') as file:\n",
    "    contractions = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_contractions(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Function to replace contractions with their longer forms\n",
    "\n",
    "    Args:\n",
    "    string text: text to replace contractions\n",
    "\n",
    "    Returns:\n",
    "    string: replaced text\n",
    "    \"\"\"\n",
    "    new_test = []\n",
    "    for t in text.split():\n",
    "        if t.lower() in contractions.keys():\n",
    "            new_test.append(contractions[t.lower()])\n",
    "        else:\n",
    "            new_test.append(t)\n",
    "\n",
    "    return ' '.join(new_test)\n",
    "\n",
    "    ## TODO: ????\n",
    "    # assert 'contractions' in globals(), \"Json file with contractions not loaded\"\n",
    "    # return contractions[text.lower()] if text.lower() in contractions.keys() else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['without_contractions']=df['lower_text'].apply(remove_contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Data cleaning from noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Removing noise from each line.\n",
    "Noise is considered to be things that do not carry the useful information that the user wants to convey in the text. (№,#,%, hyperlinks, URL, etc.)\n",
    "\n",
    "Emojis may also appear in the text. In some situations, they make sense. Script converts them into text for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re, itertools, emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Function to get rif off unwanted patterns\n",
    "    Args:\n",
    "    string text: text to clean\n",
    "\n",
    "    Returns:\n",
    "    string: replaced text\n",
    "    \"\"\"\n",
    "    # Remove hashtag while keeping hashtag text\n",
    "    text = re.sub(r'#','', text)\n",
    "    # Remove HTML special entities (e.g. &amp;)\n",
    "    text = re.sub(r'\\&\\w*;', '', text)\n",
    "    # Remove tickers\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*\\/\\w*', '', text)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    text = re.sub(r'\\s\\s+','', text)\n",
    "    text = re.sub(r'[ ]{2, }',' ',text)\n",
    "    # Remove URL, RT, mention(@)\n",
    "    text=  re.sub(r'http(\\S)+', '',text)\n",
    "    text=  re.sub(r'http ...', '',text)\n",
    "    text=  re.sub(r'(RT|rt)[ ]*@[ ]*[\\S]+','',text)\n",
    "    text=  re.sub(r'RT[ ]?@','',text)\n",
    "    text = re.sub(r'@[\\S]+','',text)\n",
    "\n",
    "    # TODO: why?? example id:13\n",
    "    #Remove words with 4 or fewer letters\n",
    "    #text = re.sub(r'\\b\\w{1,4}\\b', '', text)\n",
    "\n",
    "\n",
    "    #&, < and >\n",
    "    text = re.sub(r'&amp;?', 'and',text)\n",
    "    text = re.sub(r'&lt;','<',text)\n",
    "    text = re.sub(r'&gt;','>',text)\n",
    "    # Remove characters beyond Basic Multilingual Plane (BMP) of Unicode:\n",
    "    text= ''.join(c for c in text if c <= '\\uFFFF')\n",
    "    text = text.strip()\n",
    "    # Remove misspelling words\n",
    "    text = ''.join(''.join(s)[:2] for _, s in itertools.groupby(text))\n",
    "\n",
    "    # TODO:\n",
    "    # Remove emoji\n",
    "    text = emoji.demojize(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub(\"([^\\x00-\\x7F])+\",\" \",text)\n",
    "    # Remove Mojibake (also extra spaces)\n",
    "    text = ' '.join(re.sub(\"[^\\u4e00-\\u9fa5\\u0030-\\u0039\\u0041-\\u005a\\u0061-\\u007a]\", \" \", text).split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['without_noise'] = df['without_contractions'].apply(clean_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Stop words - These are words that do not carry a semantic load, so their usefulness and role for searching is not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS as stop\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A collection of words and punctuation marks to remove from tweets\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str) -> str:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip().replace('.',' ').replace(',',' '))\n",
    "    return \" \".join(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['without_stopwords'] = df['without_noise'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## language detection??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Eng or another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Tokenization is the process of demarcating and possibly classifying sections of a string of input characters.\n",
    "The resulting tokens are then passed on to some other form of processing.\n",
    "\n",
    "In our case, we split the text into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['tokenized'] = df['without_stopwords'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Add parts of speech tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Part of speech is a category of words that have similar grammatical properties.\n",
    "\n",
    "- CC: conjunction, coordinating\n",
    "- CD: numeral, cardinal\n",
    "- DT: determiner\n",
    "- EX: existential there\n",
    "- IN: preposition or conjunction, subordinating\n",
    "- JJ: adjective or numeral, ordinal\n",
    "- JJR: adjective, comparative\n",
    "- JJS: adjective, superlative\n",
    "- LS: list item marker\n",
    "- MD: modal auxiliary\n",
    "- NN: noun, common, singular or mass\n",
    "- NNP: noun, proper, singular\n",
    "- NNS: noun, common, plural\n",
    "- PDT: pre-determiner\n",
    "- POS: genitive marker\n",
    "- PRP: pronoun, personal\n",
    "- PRP$: pronoun, possessive\n",
    "- RB: adverb\n",
    "- RBR: adverb, comparative\n",
    "- RBS: adverb, superlative\n",
    "- RP: particle\n",
    "- TO: \"to\" as preposition or infinitive marker\n",
    "- UH: interjection\n",
    "- VB: verb, base form\n",
    "- VBD: verb, past tense\n",
    "- VBG: verb, present participle or gerund\n",
    "- VBN: verb, past participle\n",
    "- VBP: verb, present tense, not 3rd person singular\n",
    "- VBZ: verb, present tense, 3rd person singular\n",
    "- WDT: WH-determiner\n",
    "- WP: WH-pronoun\n",
    "- WRB: Wh-adverb\n",
    "\n",
    "[Details](https://stackoverflow.com/questions/15388831/what-are-all-possible-pos-tags-of-nltk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df['pos_tags'] = df['tokenized'].apply(pos_tag)\n",
    "except LookupError:\n",
    "    import nltk\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    df['pos_tags'] = df['tokenized'].apply(pos_tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Lemmatization is the process of reducing a word form to a lemma.\n",
    "Lemma — its normal (dictionary) form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatization(words: list) -> list:\n",
    "    new_list = []\n",
    "    l = WordNetLemmatizer()\n",
    "\n",
    "    for w in words:\n",
    "        new_list.append(l.lemmatize(w))\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['lemmatized'] = df['tokenized'].apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>lower_text</th>\n",
       "      <th>without_contractions</th>\n",
       "      <th>without_noise</th>\n",
       "      <th>without_stopwords</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>[deeds, reason, earthquake, may, allah, forgiv...</td>\n",
       "      <td>[(deeds, NNS), (reason, NN), (earthquake, NN),...</td>\n",
       "      <td>[deed, reason, earthquake, may, allah, forgive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[(forest, JJS), (fire, NN), (near, IN), (la, J...</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>[residents, asked, shelter, place, notified, o...</td>\n",
       "      <td>[(residents, NNS), (asked, VBD), (shelter, JJ)...</td>\n",
       "      <td>[resident, asked, shelter, place, notified, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>13 00 people receive wildfires evacuation orde...</td>\n",
       "      <td>13 00 people receive wildfires evacuation orde...</td>\n",
       "      <td>[13, 00, people, receive, wildfires, evacuatio...</td>\n",
       "      <td>[(13, CD), (00, CD), (people, NNS), (receive, ...</td>\n",
       "      <td>[13, 00, people, receive, wildfire, evacuation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[(got, VBD), (sent, JJ), (photo, NN), (ruby, N...</td>\n",
       "      <td>[got, sent, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "      <td>#rockyfire update =&gt; california hwy. 20 closed...</td>\n",
       "      <td>#rockyfire update =&gt; california hwy. 20 closed...</td>\n",
       "      <td>rockyfire update california hwy 20 closed in b...</td>\n",
       "      <td>rockyfire update california hwy 20 closed dire...</td>\n",
       "      <td>[rockyfire, update, california, hwy, 20, close...</td>\n",
       "      <td>[(rockyfire, NN), (update, NN), (california, N...</td>\n",
       "      <td>[rockyfire, update, california, hwy, 20, close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
       "      <td>flood disaster heavy rain causes flash floodin...</td>\n",
       "      <td>flood disaster heavy rain causes flash floodin...</td>\n",
       "      <td>[flood, disaster, heavy, rain, causes, flash, ...</td>\n",
       "      <td>[(flood, NN), (disaster, NN), (heavy, JJ), (ra...</td>\n",
       "      <td>[flood, disaster, heavy, rain, cause, flash, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "      <td>i'm on top of the hill and i can see a fire in...</td>\n",
       "      <td>i am on top of the hill and i can see a fire i...</td>\n",
       "      <td>i am on top of the hill and i can see a fire i...</td>\n",
       "      <td>top hill see fire woods</td>\n",
       "      <td>[top, hill, see, fire, woods]</td>\n",
       "      <td>[(top, JJ), (hill, NN), (see, VBP), (fire, NN)...</td>\n",
       "      <td>[top, hill, see, fire, wood]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "      <td>there's an emergency evacuation happening now ...</td>\n",
       "      <td>there is an emergency evacuation happening now...</td>\n",
       "      <td>there is an emergency evacuation happening now...</td>\n",
       "      <td>emergency evacuation happening now building ac...</td>\n",
       "      <td>[emergency, evacuation, happening, now, buildi...</td>\n",
       "      <td>[(emergency, NN), (evacuation, NN), (happening...</td>\n",
       "      <td>[emergency, evacuation, happening, now, buildi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "      <td>i'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>i am afraid that the tornado is coming to our ...</td>\n",
       "      <td>i am afraid that the tornado is coming to our ...</td>\n",
       "      <td>afraid tornado coming area</td>\n",
       "      <td>[afraid, tornado, coming, area]</td>\n",
       "      <td>[(afraid, JJ), (tornado, NN), (coming, VBG), (...</td>\n",
       "      <td>[afraid, tornado, coming, area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three people died from the heat wave so far</td>\n",
       "      <td>1</td>\n",
       "      <td>three people died from the heat wave so far</td>\n",
       "      <td>three people died from the heat wave so far</td>\n",
       "      <td>three people died from the heat wave so far</td>\n",
       "      <td>three people died heat wave far</td>\n",
       "      <td>[three, people, died, heat, wave, far]</td>\n",
       "      <td>[(three, CD), (people, NNS), (died, VBD), (hea...</td>\n",
       "      <td>[three, people, died, heat, wave, far]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Haha South Tampa is getting flooded hah- WAIT ...</td>\n",
       "      <td>1</td>\n",
       "      <td>haha south tampa is getting flooded hah- wait ...</td>\n",
       "      <td>haha south tampa is getting flooded hah- wait ...</td>\n",
       "      <td>haha south tampa is getting flooded hah wait a...</td>\n",
       "      <td>haha south tampa getting flooded hah wait seco...</td>\n",
       "      <td>[haha, south, tampa, getting, flooded, hah, wa...</td>\n",
       "      <td>[(haha, NN), (south, NN), (tampa, IN), (gettin...</td>\n",
       "      <td>[haha, south, tampa, getting, flooded, hah, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #Florida #TampaBay #Tampa 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>#raining #flooding #florida #tampabay #tampa 1...</td>\n",
       "      <td>#raining #flooding #florida #tampabay #tampa 1...</td>\n",
       "      <td>raining flooding florida tampabay tampa 18 or ...</td>\n",
       "      <td>raining flooding florida tampabay tampa 18 19 ...</td>\n",
       "      <td>[raining, flooding, florida, tampabay, tampa, ...</td>\n",
       "      <td>[(raining, VBG), (flooding, VBG), (florida, JJ...</td>\n",
       "      <td>[raining, flooding, florida, tampabay, tampa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Flood in Bago Myanmar #We arrived Bago</td>\n",
       "      <td>1</td>\n",
       "      <td>#flood in bago myanmar #we arrived bago</td>\n",
       "      <td>#flood in bago myanmar #we arrived bago</td>\n",
       "      <td>flood in bago myanmar we arrived bago</td>\n",
       "      <td>flood bago myanmar arrived bago</td>\n",
       "      <td>[flood, bago, myanmar, arrived, bago]</td>\n",
       "      <td>[(flood, NN), (bago, NN), (myanmar, NN), (arri...</td>\n",
       "      <td>[flood, bago, myanmar, arrived, bago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1</td>\n",
       "      <td>damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>damage school bus 80 multi car crash breaking</td>\n",
       "      <td>[damage, school, bus, 80, multi, car, crash, b...</td>\n",
       "      <td>[(damage, NN), (school, NN), (bus, NN), (80, C...</td>\n",
       "      <td>[damage, school, bus, 80, multi, car, crash, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword location                                               text  \\\n",
       "0    1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1    4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2    5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3    6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4    7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5    8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6   10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7   13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8   14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9   15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "10  16     NaN      NaN        Three people died from the heat wave so far   \n",
       "11  17     NaN      NaN  Haha South Tampa is getting flooded hah- WAIT ...   \n",
       "12  18     NaN      NaN  #raining #flooding #Florida #TampaBay #Tampa 1...   \n",
       "13  19     NaN      NaN            #Flood in Bago Myanmar #We arrived Bago   \n",
       "14  20     NaN      NaN  Damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "    target                                         lower_text  \\\n",
       "0        1  our deeds are the reason of this #earthquake m...   \n",
       "1        1             forest fire near la ronge sask. canada   \n",
       "2        1  all residents asked to 'shelter in place' are ...   \n",
       "3        1  13,000 people receive #wildfires evacuation or...   \n",
       "4        1  just got sent this photo from ruby #alaska as ...   \n",
       "5        1  #rockyfire update => california hwy. 20 closed...   \n",
       "6        1  #flood #disaster heavy rain causes flash flood...   \n",
       "7        1  i'm on top of the hill and i can see a fire in...   \n",
       "8        1  there's an emergency evacuation happening now ...   \n",
       "9        1  i'm afraid that the tornado is coming to our a...   \n",
       "10       1        three people died from the heat wave so far   \n",
       "11       1  haha south tampa is getting flooded hah- wait ...   \n",
       "12       1  #raining #flooding #florida #tampabay #tampa 1...   \n",
       "13       1            #flood in bago myanmar #we arrived bago   \n",
       "14       1  damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "                                 without_contractions  \\\n",
       "0   our deeds are the reason of this #earthquake m...   \n",
       "1              forest fire near la ronge sask. canada   \n",
       "2   all residents asked to 'shelter in place' are ...   \n",
       "3   13,000 people receive #wildfires evacuation or...   \n",
       "4   just got sent this photo from ruby #alaska as ...   \n",
       "5   #rockyfire update => california hwy. 20 closed...   \n",
       "6   #flood #disaster heavy rain causes flash flood...   \n",
       "7   i am on top of the hill and i can see a fire i...   \n",
       "8   there is an emergency evacuation happening now...   \n",
       "9   i am afraid that the tornado is coming to our ...   \n",
       "10        three people died from the heat wave so far   \n",
       "11  haha south tampa is getting flooded hah- wait ...   \n",
       "12  #raining #flooding #florida #tampabay #tampa 1...   \n",
       "13            #flood in bago myanmar #we arrived bago   \n",
       "14  damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "                                        without_noise  \\\n",
       "0   our deeds are the reason of this earthquake ma...   \n",
       "1               forest fire near la ronge sask canada   \n",
       "2   all residents asked to shelter in place are be...   \n",
       "3   13 00 people receive wildfires evacuation orde...   \n",
       "4   just got sent this photo from ruby alaska as s...   \n",
       "5   rockyfire update california hwy 20 closed in b...   \n",
       "6   flood disaster heavy rain causes flash floodin...   \n",
       "7   i am on top of the hill and i can see a fire i...   \n",
       "8   there is an emergency evacuation happening now...   \n",
       "9   i am afraid that the tornado is coming to our ...   \n",
       "10        three people died from the heat wave so far   \n",
       "11  haha south tampa is getting flooded hah wait a...   \n",
       "12  raining flooding florida tampabay tampa 18 or ...   \n",
       "13              flood in bago myanmar we arrived bago   \n",
       "14  damage to school bus on 80 in multi car crash ...   \n",
       "\n",
       "                                    without_stopwords  \\\n",
       "0        deeds reason earthquake may allah forgive us   \n",
       "1               forest fire near la ronge sask canada   \n",
       "2   residents asked shelter place notified officer...   \n",
       "3   13 00 people receive wildfires evacuation orde...   \n",
       "4   got sent photo ruby alaska smoke wildfires pou...   \n",
       "5   rockyfire update california hwy 20 closed dire...   \n",
       "6   flood disaster heavy rain causes flash floodin...   \n",
       "7                             top hill see fire woods   \n",
       "8   emergency evacuation happening now building ac...   \n",
       "9                          afraid tornado coming area   \n",
       "10                    three people died heat wave far   \n",
       "11  haha south tampa getting flooded hah wait seco...   \n",
       "12  raining flooding florida tampabay tampa 18 19 ...   \n",
       "13                    flood bago myanmar arrived bago   \n",
       "14      damage school bus 80 multi car crash breaking   \n",
       "\n",
       "                                            tokenized  \\\n",
       "0   [deeds, reason, earthquake, may, allah, forgiv...   \n",
       "1       [forest, fire, near, la, ronge, sask, canada]   \n",
       "2   [residents, asked, shelter, place, notified, o...   \n",
       "3   [13, 00, people, receive, wildfires, evacuatio...   \n",
       "4   [got, sent, photo, ruby, alaska, smoke, wildfi...   \n",
       "5   [rockyfire, update, california, hwy, 20, close...   \n",
       "6   [flood, disaster, heavy, rain, causes, flash, ...   \n",
       "7                       [top, hill, see, fire, woods]   \n",
       "8   [emergency, evacuation, happening, now, buildi...   \n",
       "9                     [afraid, tornado, coming, area]   \n",
       "10             [three, people, died, heat, wave, far]   \n",
       "11  [haha, south, tampa, getting, flooded, hah, wa...   \n",
       "12  [raining, flooding, florida, tampabay, tampa, ...   \n",
       "13              [flood, bago, myanmar, arrived, bago]   \n",
       "14  [damage, school, bus, 80, multi, car, crash, b...   \n",
       "\n",
       "                                             pos_tags  \\\n",
       "0   [(deeds, NNS), (reason, NN), (earthquake, NN),...   \n",
       "1   [(forest, JJS), (fire, NN), (near, IN), (la, J...   \n",
       "2   [(residents, NNS), (asked, VBD), (shelter, JJ)...   \n",
       "3   [(13, CD), (00, CD), (people, NNS), (receive, ...   \n",
       "4   [(got, VBD), (sent, JJ), (photo, NN), (ruby, N...   \n",
       "5   [(rockyfire, NN), (update, NN), (california, N...   \n",
       "6   [(flood, NN), (disaster, NN), (heavy, JJ), (ra...   \n",
       "7   [(top, JJ), (hill, NN), (see, VBP), (fire, NN)...   \n",
       "8   [(emergency, NN), (evacuation, NN), (happening...   \n",
       "9   [(afraid, JJ), (tornado, NN), (coming, VBG), (...   \n",
       "10  [(three, CD), (people, NNS), (died, VBD), (hea...   \n",
       "11  [(haha, NN), (south, NN), (tampa, IN), (gettin...   \n",
       "12  [(raining, VBG), (flooding, VBG), (florida, JJ...   \n",
       "13  [(flood, NN), (bago, NN), (myanmar, NN), (arri...   \n",
       "14  [(damage, NN), (school, NN), (bus, NN), (80, C...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   [deed, reason, earthquake, may, allah, forgive...  \n",
       "1       [forest, fire, near, la, ronge, sask, canada]  \n",
       "2   [resident, asked, shelter, place, notified, of...  \n",
       "3   [13, 00, people, receive, wildfire, evacuation...  \n",
       "4   [got, sent, photo, ruby, alaska, smoke, wildfi...  \n",
       "5   [rockyfire, update, california, hwy, 20, close...  \n",
       "6   [flood, disaster, heavy, rain, cause, flash, f...  \n",
       "7                        [top, hill, see, fire, wood]  \n",
       "8   [emergency, evacuation, happening, now, buildi...  \n",
       "9                     [afraid, tornado, coming, area]  \n",
       "10             [three, people, died, heat, wave, far]  \n",
       "11  [haha, south, tampa, getting, flooded, hah, wa...  \n",
       "12  [raining, flooding, florida, tampabay, tampa, ...  \n",
       "13              [flood, bago, myanmar, arrived, bago]  \n",
       "14  [damage, school, bus, 80, multi, car, crash, b...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Save clear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CLEAR_PATH = r\"../data/clear/\"\n",
    "NAME = f\"clear_{datetime.utcnow().strftime('%Y%m%d_%H%M%S_%f')[:-3]}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(CLEAR_PATH+NAME, encoding='utf-8', index=False, sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "58693017578f28d6f3ba0f029e52a3bdd88659d4d6650f524ea9bd9e8228a36d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
